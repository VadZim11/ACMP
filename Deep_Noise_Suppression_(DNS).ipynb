{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Deep Noise Suppression (DNS).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadZim11/ACMP/blob/master/Deep_Noise_Suppression_(DNS).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6MAl-y7fblT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e27c939b-dad1-462a-8116-f68879db1a04"
      },
      "source": [
        "!pip install soundfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import subprocess\n",
        "import glob\n",
        "import librosa\n",
        "import random\n",
        "import tempfile"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeoff2svfble",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPS = np.finfo(float).eps\n",
        "np.random.seed(0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v7XnUtCfbln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2f7fdef-4094-4ae8-f3e9-90587e966815"
      },
      "source": [
        "EPS"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.220446049250313e-16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGYf1Izvfblw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_clipped(audio, clipping_threshold=0.99):\n",
        "    return any(abs(audio) > clipping_threshold)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9sNubMBfbl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(audio, target_level=-25):\n",
        "    '''Normalize the signal to the target level'''\n",
        "    rms = (audio ** 2).mean() ** 0.5\n",
        "    scalar = 10 ** (target_level / 20) / (rms+EPS)\n",
        "    audio = audio * scalar\n",
        "    return audio"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ4DUH9nfbl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_segmental_rms(audio, rms, target_level=-25):\n",
        "    '''Normalize the signal to the target level\n",
        "    based on segmental RMS'''\n",
        "    scalar = 10 ** (target_level / 20) / (rms+EPS)\n",
        "    audio = audio * scalar\n",
        "    return audio"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trW6pjeyfbmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def audioread(path, norm=False, start=0, stop=None, target_level=-25):\n",
        "    '''Function to read audio'''\n",
        "\n",
        "    path = os.path.abspath(path)\n",
        "    if not os.path.exists(path):\n",
        "        raise ValueError(\"[{}] does not exist!\".format(path))\n",
        "    try:\n",
        "        audio, sample_rate = sf.read(path, start=start, stop=stop)\n",
        "    except RuntimeError:  # fix for sph pcm-embedded shortened v2\n",
        "        print('WARNING: Audio type not supported')\n",
        "\n",
        "    if len(audio.shape) == 1:  # mono\n",
        "        if norm:\n",
        "            rms = (audio ** 2).mean() ** 0.5\n",
        "            scalar = 10 ** (target_level / 20) / (rms+EPS)\n",
        "            audio = audio * scalar\n",
        "    else:  # multi-channel\n",
        "        audio = audio.T\n",
        "        audio = audio.sum(axis=0)/audio.shape[0]\n",
        "        if norm:\n",
        "            audio = normalize(audio, target_level)\n",
        "\n",
        "    return audio, sample_rate"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faRsKPYNfbmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def audiowrite(destpath, audio, sample_rate=16000, norm=False, target_level=-25, \\\n",
        "                clipping_threshold=0.99, clip_test=False):\n",
        "    '''Function to write audio'''\n",
        "\n",
        "    if clip_test:\n",
        "        if is_clipped(audio, clipping_threshold=clipping_threshold):\n",
        "            raise ValueError(\"Clipping detected in audiowrite()! \" + \\\n",
        "                            destpath + \" file not written to disk.\")\n",
        "\n",
        "    if norm:\n",
        "        audio = normalize(audio, target_level)\n",
        "        max_amp = max(abs(audio))\n",
        "        if max_amp >= clipping_threshold:\n",
        "            audio = audio/max_amp * (clipping_threshold-EPS)\n",
        "\n",
        "    destpath = os.path.abspath(destpath)\n",
        "    destdir = os.path.dirname(destpath)\n",
        "\n",
        "    if not os.path.exists(destdir):\n",
        "        os.makedirs(destdir)\n",
        "\n",
        "    sf.write(destpath, audio, sample_rate)\n",
        "    return"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtrCifIfbmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_reverb(sasxExe, input_wav, filter_file, output_wav):\n",
        "    ''' Function to add reverb'''\n",
        "    command_sasx_apply_reverb = \"{0} -r {1} \\\n",
        "        -f {2} -o {3}\".format(sasxExe, input_wav, filter_file, output_wav)\n",
        "                                                               \n",
        "    subprocess.call(command_sasx_apply_reverb)\n",
        "    return output_wav"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYHqLcXofbmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_clipping(audio, max_thresh_perc=0.8):\n",
        "    '''Function to add clipping'''\n",
        "    threshold = max(abs(audio))*max_thresh_perc\n",
        "    audioclipped = np.clip(audio, -threshold, threshold)\n",
        "    return audioclipped"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3g2ruhfbma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adsp_filter(Adspvqe, nearEndInput, nearEndOutput, farEndInput):\n",
        "\n",
        "    command_adsp_clean = \"{0} --breakOnErrors 0 --sampleRate 16000 --useEchoCancellation 0 \\\n",
        "                    --operatingMode 2 --useDigitalAgcNearend 0 --useDigitalAgcFarend 0 \\\n",
        "                    --useVirtualAGC 0 --useComfortNoiseGenerator 0 --useAnalogAutomaticGainControl 0 \\\n",
        "                    --useNoiseReduction 0 --loopbackInputFile {1} --farEndInputFile {2} \\\n",
        "                    --nearEndInputFile {3} --nearEndOutputFile {4}\".format(Adspvqe,\n",
        "                                farEndInput, farEndInput, nearEndInput, nearEndOutput)\n",
        "    subprocess.call(command_adsp_clean)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB11AVKSfbmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def snr_mixer(params, clean, noise, snr, target_level=-25, clipping_threshold=0.99):\n",
        "    '''Function to mix clean speech and noise at various SNR levels'''\n",
        "    cfg = params['cfg']\n",
        "    if len(clean) > len(noise):\n",
        "        noise = np.append(noise, np.zeros(len(clean)-len(noise)))\n",
        "    else:\n",
        "        clean = np.append(clean, np.zeros(len(noise)-len(clean)))\n",
        "\n",
        "    # Normalizing to -25 dB FS\n",
        "    clean = clean/(max(abs(clean))+EPS)\n",
        "    clean = normalize(clean, target_level)\n",
        "    rmsclean = (clean**2).mean()**0.5\n",
        "\n",
        "    noise = noise/(max(abs(noise))+EPS)\n",
        "    noise = normalize(noise, target_level)\n",
        "    rmsnoise = (noise**2).mean()**0.5\n",
        "\n",
        "    # Set the noise level for a given SNR\n",
        "    noisescalar = rmsclean / (10**(snr/20)) / (rmsnoise+EPS)\n",
        "    noisenewlevel = noise * noisescalar\n",
        "\n",
        "    # Mix noise and clean speech\n",
        "    noisyspeech = clean + noisenewlevel\n",
        "    \n",
        "    # Randomly select RMS value between -15 dBFS and -35 dBFS and normalize noisyspeech with that value\n",
        "    # There is a chance of clipping that might happen with very less probability, which is not a major issue. \n",
        "    noisy_rms_level = np.random.randint(params['target_level_lower'], params['target_level_upper'])\n",
        "    rmsnoisy = (noisyspeech**2).mean()**0.5\n",
        "    scalarnoisy = 10 ** (noisy_rms_level / 20) / (rmsnoisy+EPS)\n",
        "    noisyspeech = noisyspeech * scalarnoisy\n",
        "    clean = clean * scalarnoisy\n",
        "    noisenewlevel = noisenewlevel * scalarnoisy\n",
        "\n",
        "    # Final check to see if there are any amplitudes exceeding +/- 1. If so, normalize all the signals accordingly\n",
        "    if is_clipped(noisyspeech):\n",
        "        noisyspeech_maxamplevel = max(abs(noisyspeech))/(clipping_threshold-EPS)\n",
        "        noisyspeech = noisyspeech/noisyspeech_maxamplevel\n",
        "        clean = clean/noisyspeech_maxamplevel\n",
        "        noisenewlevel = noisenewlevel/noisyspeech_maxamplevel\n",
        "        noisy_rms_level = int(20*np.log10(scalarnoisy/noisyspeech_maxamplevel*(rmsnoisy+EPS)))\n",
        "\n",
        "    return clean, noisenewlevel, noisyspeech, noisy_rms_level\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wDfkGSxfbml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmental_snr_mixer(params, clean, noise, snr, target_level=-25, clipping_threshold=0.99):\n",
        "    '''Function to mix clean speech and noise at various segmental SNR levels'''\n",
        "    cfg = params['cfg']\n",
        "    if len(clean) > len(noise):\n",
        "        noise = np.append(noise, np.zeros(len(clean)-len(noise)))\n",
        "    else:\n",
        "        clean = np.append(clean, np.zeros(len(noise)-len(clean)))\n",
        "    clean = clean/(max(abs(clean))+EPS)\n",
        "    noise = noise/(max(abs(noise))+EPS)\n",
        "    rmsclean, rmsnoise = active_rms(clean=clean, noise=noise)\n",
        "    clean = normalize_segmental_rms(clean, rms=rmsclean, target_level=target_level)\n",
        "    noise = normalize_segmental_rms(noise, rms=rmsnoise, target_level=target_level)\n",
        "    # Set the noise level for a given SNR\n",
        "    noisescalar = rmsclean / (10**(snr/20)) / (rmsnoise+EPS)\n",
        "    noisenewlevel = noise * noisescalar\n",
        "\n",
        "    # Mix noise and clean speech\n",
        "    noisyspeech = clean + noisenewlevel\n",
        "    # Randomly select RMS value between -15 dBFS and -35 dBFS and normalize noisyspeech with that value\n",
        "    # There is a chance of clipping that might happen with very less probability, which is not a major issue. \n",
        "    noisy_rms_level = np.random.randint(params['target_level_lower'], params['target_level_upper'])\n",
        "    rmsnoisy = (noisyspeech**2).mean()**0.5\n",
        "    scalarnoisy = 10 ** (noisy_rms_level / 20) / (rmsnoisy+EPS)\n",
        "    noisyspeech = noisyspeech * scalarnoisy\n",
        "    clean = clean * scalarnoisy\n",
        "    noisenewlevel = noisenewlevel * scalarnoisy\n",
        "    # Final check to see if there are any amplitudes exceeding +/- 1. If so, normalize all the signals accordingly\n",
        "    if is_clipped(noisyspeech):\n",
        "        noisyspeech_maxamplevel = max(abs(noisyspeech))/(clipping_threshold-EPS)\n",
        "        noisyspeech = noisyspeech/noisyspeech_maxamplevel\n",
        "        clean = clean/noisyspeech_maxamplevel\n",
        "        noisenewlevel = noisenewlevel/noisyspeech_maxamplevel\n",
        "        noisy_rms_level = int(20*np.log10(scalarnoisy/noisyspeech_maxamplevel*(rmsnoisy+EPS)))\n",
        "\n",
        "    return clean, noisenewlevel, noisyspeech, noisy_rms_level"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1d5kASfbmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def active_rms(clean, noise, fs=16000, energy_thresh=-50):\n",
        "    '''Returns the clean and noise RMS of the noise calculated only in the active portions'''\n",
        "    window_size = 100 # in ms\n",
        "    window_samples = int(fs*window_size/1000)\n",
        "    sample_start = 0\n",
        "    noise_active_segs = []\n",
        "    clean_active_segs = []\n",
        "\n",
        "    while sample_start < len(noise):\n",
        "        sample_end = min(sample_start + window_samples, len(noise))\n",
        "        noise_win = noise[sample_start:sample_end]\n",
        "        clean_win = clean[sample_start:sample_end]\n",
        "        noise_seg_rms = 20*np.log10((noise_win**2).mean()+EPS)\n",
        "        # Considering frames with energy\n",
        "        if noise_seg_rms > energy_thresh:\n",
        "            noise_active_segs = np.append(noise_active_segs, noise_win)\n",
        "            clean_active_segs = np.append(clean_active_segs, clean_win)\n",
        "        sample_start += window_samples\n",
        "\n",
        "    if len(noise_active_segs)!=0:\n",
        "        noise_rms = (noise_active_segs**2).mean()**0.5\n",
        "    else:\n",
        "        noise_rms = EPS\n",
        "        \n",
        "    if len(clean_active_segs)!=0:\n",
        "        clean_rms = (clean_active_segs**2).mean()**0.5\n",
        "    else:\n",
        "        clean_rms = EPS\n",
        "\n",
        "    return clean_rms, noise_rms"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChnDmnuefbmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activitydetector(audio, fs=16000, energy_thresh=0.13, target_level=-25):\n",
        "    '''Return the percentage of the time the audio signal is above an energy threshold'''\n",
        "\n",
        "    audio = normalize(audio, target_level)\n",
        "    window_size = 50 # in ms\n",
        "    window_samples = int(fs*window_size/1000)\n",
        "    sample_start = 0\n",
        "    cnt = 0\n",
        "    prev_energy_prob = 0\n",
        "    active_frames = 0\n",
        "\n",
        "    a = -1\n",
        "    b = 0.2\n",
        "    alpha_rel = 0.05\n",
        "    alpha_att = 0.8\n",
        "\n",
        "    while sample_start < len(audio):\n",
        "        sample_end = min(sample_start + window_samples, len(audio))\n",
        "        audio_win = audio[sample_start:sample_end]\n",
        "        frame_rms = 20*np.log10(sum(audio_win**2)+EPS)\n",
        "        frame_energy_prob = 1./(1+np.exp(-(a+b*frame_rms)))\n",
        "\n",
        "        if frame_energy_prob > prev_energy_prob:\n",
        "            smoothed_energy_prob = frame_energy_prob*alpha_att + prev_energy_prob*(1-alpha_att)\n",
        "        else:\n",
        "            smoothed_energy_prob = frame_energy_prob*alpha_rel + prev_energy_prob*(1-alpha_rel)\n",
        "\n",
        "        if smoothed_energy_prob > energy_thresh:\n",
        "            active_frames += 1\n",
        "        prev_energy_prob = frame_energy_prob\n",
        "        sample_start += window_samples\n",
        "        cnt += 1\n",
        "\n",
        "    perc_active = active_frames/cnt\n",
        "    return perc_active\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOtlfOkIfbm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resampler(input_dir, target_sr=16000, ext='*.wav'):\n",
        "    '''Resamples the audio files in input_dir to target_sr'''\n",
        "    files = glob.glob(f\"{input_dir}/\"+ext)\n",
        "    for pathname in files:\n",
        "        print(pathname)\n",
        "        try:\n",
        "            audio, fs = audioread(pathname)\n",
        "            audio_resampled = librosa.core.resample(audio, fs, target_sr)\n",
        "            audiowrite(pathname, audio_resampled, target_sr)\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgJukWKfbm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def audio_segmenter(input_dir, dest_dir, segment_len=10, ext='*.wav'):\n",
        "    '''Segments the audio clips in dir to segment_len in secs'''\n",
        "    files = glob.glob(f\"{input_dir}/\"+ext)\n",
        "    for i in range(len(files)):\n",
        "        audio, fs = audioread(files[i])\n",
        "        \n",
        "        if len(audio) > (segment_len*fs) and len(audio)%(segment_len*fs) != 0:\n",
        "            audio = np.append(audio, audio[0 : segment_len*fs - (len(audio)%(segment_len*fs))]) \n",
        "        if len(audio) < (segment_len*fs):\n",
        "            while len(audio) < (segment_len*fs):\n",
        "                audio = np.append(audio, audio)\n",
        "            audio = audio[:segment_len*fs]\n",
        "        \n",
        "        num_segments = int(len(audio)/(segment_len*fs))\n",
        "        audio_segments = np.split(audio, num_segments)\n",
        "\n",
        "        basefilename = os.path.basename(files[i])\n",
        "        basename, ext = os.path.splitext(basefilename)\n",
        "\n",
        "        for j in range(len(audio_segments)):\n",
        "            newname = basename+'_'+str(j)+ext\n",
        "            destpath = os.path.join(dest_dir,newname)\n",
        "            audiowrite(destpath, audio_segments[j], fs)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR41WrTlfbnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import ast\n",
        "import configparser as CP\n",
        "from itertools import repeat\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "import random\n",
        "from random import shuffle\n",
        "import librosa\n",
        "import numpy as np\n",
        "import utils"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUQVe45Tfbn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROCESSES = multiprocessing.cpu_count()\n",
        "MAXTRIES = 50\n",
        "MAXFILELEN = 100\n",
        "\n",
        "np.random.seed(2)\n",
        "random.seed(3)\n",
        "\n",
        "clean_counter = None\n",
        "noise_counter = None"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MMDdzXXfbn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init(args1, args2):\n",
        "    ''' store the counter for later use '''\n",
        "    global clean_counter, noise_counter\n",
        "    clean_counter = args1\n",
        "    noise_counter = args2"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glDf_zaKfboA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_audio(is_clean, params, filenum, audio_samples_length=-1):\n",
        "    '''Construct an audio signal from source files'''\n",
        "\n",
        "    fs_output = params['fs']\n",
        "    silence_length = params['silence_length']\n",
        "    if audio_samples_length == -1:\n",
        "        audio_samples_length = int(params['audio_length']*params['fs'])\n",
        "\n",
        "    output_audio = np.zeros(0)\n",
        "    remaining_length = audio_samples_length\n",
        "    files_used = []\n",
        "    clipped_files = []\n",
        "\n",
        "    global clean_counter, noise_counter\n",
        "    if is_clean:\n",
        "        source_files = params['cleanfilenames']\n",
        "        idx_counter = clean_counter\n",
        "    else:    \n",
        "        source_files = params['noisefilenames']        \n",
        "        idx_counter = noise_counter\n",
        "\n",
        "    # initialize silence\n",
        "    silence = np.zeros(int(fs_output*silence_length))\n",
        "\n",
        "    # iterate through multiple clips until we have a long enough signal\n",
        "    tries_left = MAXTRIES\n",
        "    while remaining_length > 0 and tries_left > 0:\n",
        "\n",
        "        # read next audio file and resample if necessary\n",
        "        with idx_counter.get_lock():\n",
        "            idx_counter.value += 1\n",
        "            idx = idx_counter.value % np.size(source_files)\n",
        "\n",
        "        input_audio, fs_input = audioread(source_files[idx])\n",
        "        if fs_input != fs_output:\n",
        "            input_audio = librosa.resample(input_audio, fs_input, fs_output)\n",
        "\n",
        "        # if current file is longer than remaining desired length, and this is\n",
        "        # noise generation or this is training set, subsample it randomly\n",
        "        if len(input_audio) > remaining_length and (not is_clean or not params['is_test_set']):\n",
        "            idx_seg = np.random.randint(0, len(input_audio)-remaining_length)\n",
        "            input_audio = input_audio[idx_seg:idx_seg+remaining_length]\n",
        "\n",
        "        # check for clipping, and if found move onto next file\n",
        "        if is_clipped(input_audio):\n",
        "            clipped_files.append(source_files[idx])\n",
        "            tries_left -= 1\n",
        "            continue\n",
        "\n",
        "        # concatenate current input audio to output audio stream\n",
        "        files_used.append(source_files[idx])\n",
        "        output_audio = np.append(output_audio, input_audio)\n",
        "        remaining_length -= len(input_audio)\n",
        "\n",
        "        # add some silence if we have not reached desired audio length\n",
        "        if remaining_length > 0:\n",
        "            silence_len = min(remaining_length, len(silence))\n",
        "            output_audio = np.append(output_audio, silence[:silence_len])\n",
        "            remaining_length -= silence_len\n",
        "\n",
        "    if tries_left == 0:\n",
        "        print(\"Audio generation failed for filenum \" + str(filenum))\n",
        "        return [], [], clipped_files\n",
        "\n",
        "    return output_audio, files_used, clipped_files\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3fNO7fLfboF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_audio(is_clean, params, filenum, audio_samples_length=-1):\n",
        "    '''Calls build_audio() to get an audio signal, and verify that it meets the\n",
        "       activity threshold'''\n",
        "\n",
        "    clipped_files = []\n",
        "    low_activity_files = []\n",
        "    if audio_samples_length == -1:\n",
        "        audio_samples_length = int(params['audio_length']*params['fs'])\n",
        "    if is_clean:\n",
        "        activity_threshold = params['clean_activity_threshold']\n",
        "    else:\n",
        "        activity_threshold = params['noise_activity_threshold']\n",
        "\n",
        "    while True:\n",
        "        audio, source_files, new_clipped_files = \\\n",
        "            build_audio(is_clean, params, filenum, audio_samples_length)\n",
        "\n",
        "        clipped_files += new_clipped_files\n",
        "        if len(audio) < audio_samples_length:\n",
        "            continue\n",
        "\n",
        "        if activity_threshold == 0.0:\n",
        "            break\n",
        "\n",
        "        percactive = activitydetector(audio=audio)\n",
        "        if percactive > activity_threshold:\n",
        "            break\n",
        "        else:\n",
        "            low_activity_files += source_files\n",
        "\n",
        "    return audio, source_files, clipped_files, low_activity_files"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lluqQ_VIfboL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main_gen(params, filenum):\n",
        "    '''Calls gen_audio() to generate the audio signals, verifies that they meet\n",
        "       the requirements, and writes the files to storage'''\n",
        "\n",
        "    print(\"Generating file #\" + str(filenum))\n",
        "\n",
        "    clean_clipped_files = []\n",
        "    clean_low_activity_files = []\n",
        "    noise_clipped_files = []\n",
        "    noise_low_activity_files = []\n",
        "\n",
        "    while True:\n",
        "        # generate clean speech\n",
        "        clean, clean_source_files, clean_cf, clean_laf = \\\n",
        "            gen_audio(True, params, filenum)\n",
        "        # generate noise\n",
        "        noise, noise_source_files, noise_cf, noise_laf = \\\n",
        "            gen_audio(False, params, filenum, len(clean))\n",
        "\n",
        "        clean_clipped_files += clean_cf\n",
        "        clean_low_activity_files += clean_laf\n",
        "        noise_clipped_files += noise_cf\n",
        "        noise_low_activity_files += noise_laf\n",
        "\n",
        "        # mix clean speech and noise\n",
        "        # if specified, use specified SNR value\n",
        "        if not params['randomize_snr']:\n",
        "            snr = params['snr']\n",
        "        # use a randomly sampled SNR value between the specified bounds\n",
        "        else:\n",
        "            snr = np.random.randint(params['snr_lower'], params['snr_upper'])\n",
        "            \n",
        "        clean_snr, noise_snr, noisy_snr, target_level = snr_mixer(params=params, \n",
        "                                                                  clean=clean, \n",
        "                                                                  noise=noise, \n",
        "                                                                  snr=snr)\n",
        "        # Uncomment the below lines if you need segmental SNR and comment the above lines using snr_mixer\n",
        "        #clean_snr, noise_snr, noisy_snr, target_level = segmental_snr_mixer(params=params, \n",
        "        #                                                                    clean=clean, \n",
        "        #                                                                    noise=noise, \n",
        "        #                                                                    snr=snr)\n",
        "        # unexpected clipping\n",
        "        if is_clipped(clean_snr) or is_clipped(noise_snr) or is_clipped(noisy_snr):       \n",
        "            continue\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # write resultant audio streams to files\n",
        "    hyphen = '-'\n",
        "    clean_source_filenamesonly = [i[:-4].split(os.path.sep)[-1] for i in clean_source_files]\n",
        "    clean_files_joined = hyphen.join(clean_source_filenamesonly)[:MAXFILELEN]\n",
        "    noise_source_filenamesonly = [i[:-4].split(os.path.sep)[-1] for i in noise_source_files]\n",
        "    noise_files_joined = hyphen.join(noise_source_filenamesonly)[:MAXFILELEN]\n",
        "\n",
        "    noisyfilename = clean_files_joined + '_' + noise_files_joined + '_snr' + \\\n",
        "                    str(snr) + '_fileid_' + str(filenum) + '.wav'\n",
        "    cleanfilename = 'clean_fileid_'+str(filenum)+'.wav'\n",
        "    noisefilename = 'noise_fileid_'+str(filenum)+'.wav'\n",
        "\n",
        "    noisypath = os.path.join(params['noisyspeech_dir'], noisyfilename)\n",
        "    cleanpath = os.path.join(params['clean_proc_dir'], cleanfilename)\n",
        "    noisepath = os.path.join(params['noise_proc_dir'], noisefilename)\n",
        "\n",
        "    audio_signals = [noisy_snr, clean_snr, noise_snr]\n",
        "    file_paths = [noisypath, cleanpath, noisepath]\n",
        "    \n",
        "    for i in range(len(audio_signals)):\n",
        "        try:\n",
        "            audiowrite(file_paths[i], audio_signals[i], params['fs'])\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "            pass\n",
        "\n",
        "    return clean_source_files, clean_clipped_files, clean_low_activity_files, \\\n",
        "           noise_source_files, noise_clipped_files, noise_low_activity_files\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HzlN67mfboQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_list(input_list, index):\n",
        "    output_list = [i[index] for i in input_list]\n",
        "    flat_output_list = [item for sublist in output_list for item in sublist]\n",
        "    flat_output_list = sorted(set(flat_output_list))\n",
        "    return flat_output_list"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp9fMU1TfboU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main_body():\n",
        "    '''Main body of this file'''\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Configurations: read noisyspeech_synthesizer.cfg and gather inputs\n",
        "    parser.add_argument('--cfg', default='noisyspeech_synthesizer.cfg',\n",
        "                        help='Read noisyspeech_synthesizer.cfg for all the details')\n",
        "    parser.add_argument('--cfg_str', type=str, default='noisy_speech')\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    params = dict()\n",
        "    params['args'] = args\n",
        "    cfgpath = os.path.join(os.path.dirname('__file__'), args.cfg)\n",
        "    assert os.path.exists(cfgpath), f'No configuration file as [{cfgpath}]'\n",
        "\n",
        "    cfg = CP.ConfigParser()\n",
        "    cfg._interpolation = CP.ExtendedInterpolation()\n",
        "    cfg.read(cfgpath)\n",
        "    params['cfg'] = cfg._sections[args.cfg_str]\n",
        "    cfg = params['cfg']\n",
        "\n",
        "    clean_dir = os.path.join(os.path.dirname('__file__'), 'CleanSpeech')\n",
        "    if cfg['speech_dir'] != 'None':\n",
        "        clean_dir = cfg['speech_dir']\n",
        "    if not os.path.exists:\n",
        "        assert False, ('Clean speech data is required')\n",
        "\n",
        "    noise_dir = os.path.join(os.path.dirname('__file__'), 'Noise')\n",
        "    if cfg['noise_dir'] != 'None':\n",
        "        noise_dir = cfg['noise_dir']\n",
        "    if not os.path.exists:\n",
        "        assert False, ('Noise data is required')\n",
        "\n",
        "    params['fs'] = int(cfg['sampling_rate'])\n",
        "    params['audioformat'] = cfg['audioformat']\n",
        "    params['audio_length'] = float(cfg['audio_length'])\n",
        "    params['silence_length'] = float(cfg['silence_length'])\n",
        "    params['total_hours'] = float(cfg['total_hours'])\n",
        "    \n",
        "    if cfg['fileindex_start'] != 'None' and cfg['fileindex_start'] != 'None':\n",
        "        params['fileindex_start'] = int(cfg['fileindex_start'])\n",
        "        params['fileindex_end'] = int(cfg['fileindex_end'])    \n",
        "        params['num_files'] = int(params['fileindex_end'])-int(params['fileindex_start'])\n",
        "    else:\n",
        "        params['num_files'] = int((params['total_hours']*60*60)/params['audio_length'])\n",
        "\n",
        "    print('Number of files to be synthesized:', params['num_files'])\n",
        "    params['is_test_set'] = utils.str2bool(cfg['is_test_set'])\n",
        "    params['clean_activity_threshold'] = float(cfg['clean_activity_threshold'])\n",
        "    params['noise_activity_threshold'] = float(cfg['noise_activity_threshold'])\n",
        "    params['snr_lower'] = int(cfg['snr_lower'])\n",
        "    params['snr_upper'] = int(cfg['snr_upper'])\n",
        "    params['randomize_snr'] = utils.str2bool(cfg['randomize_snr'])\n",
        "    params['target_level_lower'] = int(cfg['target_level_lower'])\n",
        "    params['target_level_upper'] = int(cfg['target_level_upper'])\n",
        "    \n",
        "    if 'snr' in cfg.keys():\n",
        "        params['snr'] = int(cfg['snr'])\n",
        "    else:\n",
        "        params['snr'] = int((params['snr_lower'] + params['snr_upper'])/2)\n",
        "\n",
        "    params['noisyspeech_dir'] = utils.get_dir(cfg, 'noisy_destination', 'noisy')\n",
        "    params['clean_proc_dir'] = utils.get_dir(cfg, 'clean_destination', 'clean')\n",
        "    params['noise_proc_dir'] = utils.get_dir(cfg, 'noise_destination', 'noise')\n",
        "\n",
        "    if 'speech_csv' in cfg.keys() and cfg['speech_csv'] != 'None':\n",
        "        cleanfilenames = pd.read_csv(cfg['speech_csv'])\n",
        "        cleanfilenames = cleanfilenames['filename']\n",
        "    else:\n",
        "        cleanfilenames = glob.glob(os.path.join(clean_dir, params['audioformat']))\n",
        "    params['cleanfilenames'] = cleanfilenames\n",
        "    shuffle(params['cleanfilenames'])\n",
        "    params['num_cleanfiles'] = len(params['cleanfilenames'])\n",
        "\n",
        "    params['noisefilenames'] = glob.glob(os.path.join(noise_dir, params['audioformat']))\n",
        "    shuffle(params['noisefilenames'])\n",
        "\n",
        "    # Invoke multiple processes and fan out calls to main_gen() to these processes\n",
        "    global clean_counter, noise_counter\n",
        "    clean_counter = multiprocessing.Value('i', 0)\n",
        "    noise_counter = multiprocessing.Value('i', 0)    \n",
        "    \n",
        "    multi_pool = multiprocessing.Pool(processes=PROCESSES, initializer = init, initargs = (clean_counter, noise_counter, ))\n",
        "    fileindices = range(params['num_files'])    \n",
        "    output_lists = multi_pool.starmap(main_gen, zip(repeat(params), fileindices))\n",
        "\n",
        "    flat_output_lists = []\n",
        "    num_lists = 6\n",
        "    for i in range(num_lists):\n",
        "        flat_output_lists.append(extract_list(output_lists, i))\n",
        "\n",
        "    # Create log directory if needed, and write log files of clipped and low activity files\n",
        "    log_dir = utils.get_dir(cfg, 'log_dir', 'Logs')\n",
        "\n",
        "    utils.write_log_file(log_dir, 'source_files.csv', flat_output_lists[0] + flat_output_lists[3])\n",
        "    utils.write_log_file(log_dir, 'clipped_files.csv', flat_output_lists[1] + flat_output_lists[4])\n",
        "    utils.write_log_file(log_dir, 'low_activity_files.csv', flat_output_lists[2] + flat_output_lists[5])\n",
        "    \n",
        "    # Compute and print stats about percentange of clipped and low activity files\n",
        "    total_clean = len(flat_output_lists[0]) + len(flat_output_lists[1]) + len(flat_output_lists[2])\n",
        "    total_noise = len(flat_output_lists[3]) + len(flat_output_lists[4]) + len(flat_output_lists[5])\n",
        "    pct_clean_clipped = round(len(flat_output_lists[1])/total_clean*100, 1)\n",
        "    pct_noise_clipped = round(len(flat_output_lists[4])/total_noise*100, 1)\n",
        "    pct_clean_low_activity = round(len(flat_output_lists[2])/total_clean*100, 1)\n",
        "    pct_noise_low_activity = round(len(flat_output_lists[5])/total_noise*100, 1)\n",
        "    \n",
        "    print(\"Of the \" + str(total_clean) + \" clean speech files analyzed, \" + str(pct_clean_clipped) + \\\n",
        "          \"% had clipping, and \" + str(pct_clean_low_activity) + \"% had low activity \" + \\\n",
        "          \"(below \" + str(params['clean_activity_threshold']*100) + \"% active percentage)\")\n",
        "    print(\"Of the \" + str(total_noise) + \" noise files analyzed, \" + str(pct_noise_clipped) + \\\n",
        "          \"% had clipping, and \" + str(pct_noise_low_activity) + \"% had low activity \" + \\\n",
        "          \"(below \" + str(params['noise_activity_threshold']*100) + \"% active percentage)\")\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOE6qkbwfbsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e737440-3bea-4596-a3e1-7ea96d239553"
      },
      "source": [
        "main_body()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of files to be synthesized: 600\n",
            "Generating file #0\n",
            "Generating file #75\n",
            "Generating file #76\n",
            "Generating file #1\n",
            "Generating file #2\n",
            "Generating file #77\n",
            "Generating file #3\n",
            "Generating file #78\n",
            "Generating file #4\n",
            "Generating file #79\n",
            "Generating file #5\n",
            "Generating file #80\n",
            "Generating file #6\n",
            "Generating file #81\n",
            "Generating file #82\n",
            "Generating file #83\n",
            "Generating file #7\n",
            "Generating file #84\n",
            "Generating file #8\n",
            "Generating file #9\n",
            "Generating file #85\n",
            "Generating file #10\n",
            "Generating file #86\n",
            "Generating file #11\n",
            "Generating file #87\n",
            "Generating file #12\n",
            "Generating file #88\n",
            "Generating file #13\n",
            "Generating file #89\n",
            "Generating file #14\n",
            "Generating file #90\n",
            "Generating file #15\n",
            "Generating file #91\n",
            "Generating file #16\n",
            "Generating file #92\n",
            "Generating file #17\n",
            "Generating file #93\n",
            "Generating file #18\n",
            "Generating file #94\n",
            "Generating file #19\n",
            "Generating file #95\n",
            "Generating file #20\n",
            "Generating file #96\n",
            "Generating file #21\n",
            "Generating file #97\n",
            "Generating file #22\n",
            "Generating file #23\n",
            "Generating file #98\n",
            "Generating file #24\n",
            "Generating file #99\n",
            "Generating file #25\n",
            "Generating file #26\n",
            "Generating file #100\n",
            "Generating file #27\n",
            "Generating file #28\n",
            "Generating file #101\n",
            "Generating file #102\n",
            "Generating file #29\n",
            "Generating file #103\n",
            "Generating file #30\n",
            "Generating file #31\n",
            "Generating file #104\n",
            "Generating file #32\n",
            "Generating file #105\n",
            "Generating file #33\n",
            "Generating file #106\n",
            "Generating file #107\n",
            "Generating file #34\n",
            "Generating file #108\n",
            "Generating file #35\n",
            "Generating file #109\n",
            "Generating file #110\n",
            "Generating file #36\n",
            "Generating file #111\n",
            "Generating file #37\n",
            "Generating file #38\n",
            "Generating file #112\n",
            "Generating file #39\n",
            "Generating file #113\n",
            "Generating file #40\n",
            "Generating file #41\n",
            "Generating file #42\n",
            "Generating file #114\n",
            "Generating file #115\n",
            "Generating file #43\n",
            "Generating file #116\n",
            "Generating file #44\n",
            "Generating file #45\n",
            "Generating file #117\n",
            "Generating file #46\n",
            "Generating file #118\n",
            "Generating file #119\n",
            "Generating file #47\n",
            "Generating file #120\n",
            "Generating file #48\n",
            "Generating file #121\n",
            "Generating file #49\n",
            "Generating file #50\n",
            "Generating file #122\n",
            "Generating file #51\n",
            "Generating file #52\n",
            "Generating file #123\n",
            "Generating file #53\n",
            "Generating file #54\n",
            "Generating file #124\n",
            "Generating file #125\n",
            "Generating file #55\n",
            "Generating file #126\n",
            "Generating file #56\n",
            "Generating file #127\n",
            "Generating file #57\n",
            "Generating file #128\n",
            "Generating file #58\n",
            "Generating file #129\n",
            "Generating file #59\n",
            "Generating file #130\n",
            "Generating file #60\n",
            "Generating file #61\n",
            "Generating file #131\n",
            "Generating file #132\n",
            "Generating file #62\n",
            "Generating file #133\n",
            "Generating file #63\n",
            "Generating file #134\n",
            "Generating file #64\n",
            "Generating file #135\n",
            "Generating file #136\n",
            "Generating file #65\n",
            "Generating file #137\n",
            "Generating file #138\n",
            "Generating file #66\n",
            "Generating file #139\n",
            "Generating file #140\n",
            "Generating file #141\n",
            "Generating file #67\n",
            "Generating file #142\n",
            "Generating file #68\n",
            "Generating file #143\n",
            "Generating file #69\n",
            "Generating file #144\n",
            "Generating file #70\n",
            "Generating file #145\n",
            "Generating file #146\n",
            "Generating file #147\n",
            "Generating file #71\n",
            "Generating file #148\n",
            "Generating file #72\n",
            "Generating file #149\n",
            "Generating file #73\n",
            "Generating file #74\n",
            "Generating file #150\n",
            "Generating file #225\n",
            "Generating file #151\n",
            "Generating file #226\n",
            "Generating file #227\n",
            "Generating file #152\n",
            "Generating file #228\n",
            "Generating file #153\n",
            "Generating file #229\n",
            "Generating file #154\n",
            "Generating file #230\n",
            "Generating file #155\n",
            "Generating file #156\n",
            "Generating file #231\n",
            "Generating file #157\n",
            "Generating file #232\n",
            "Generating file #158\n",
            "Generating file #233\n",
            "Generating file #159\n",
            "Generating file #234\n",
            "Generating file #235\n",
            "Generating file #160\n",
            "Generating file #236\n",
            "Generating file #161\n",
            "Generating file #237\n",
            "Generating file #162\n",
            "Generating file #163\n",
            "Generating file #238\n",
            "Generating file #164\n",
            "Generating file #239\n",
            "Generating file #240\n",
            "Generating file #165\n",
            "Generating file #241\n",
            "Generating file #166\n",
            "Generating file #167\n",
            "Generating file #242\n",
            "Generating file #168\n",
            "Generating file #243\n",
            "Generating file #169\n",
            "Generating file #244\n",
            "Generating file #170\n",
            "Generating file #171\n",
            "Generating file #245\n",
            "Generating file #246\n",
            "Generating file #172\n",
            "Generating file #247\n",
            "Generating file #248\n",
            "Generating file #173\n",
            "Generating file #249\n",
            "Generating file #174\n",
            "Generating file #250\n",
            "Generating file #175\n",
            "Generating file #251\n",
            "Generating file #176\n",
            "Generating file #252\n",
            "Generating file #177\n",
            "Generating file #178\n",
            "Generating file #253\n",
            "Generating file #179\n",
            "Generating file #254\n",
            "Generating file #255\n",
            "Generating file #256\n",
            "Generating file #180\n",
            "Generating file #257\n",
            "Generating file #181\n",
            "Generating file #258\n",
            "Generating file #182\n",
            "Generating file #183\n",
            "Generating file #259\n",
            "Generating file #260\n",
            "Generating file #184\n",
            "Generating file #261\n",
            "Generating file #185\n",
            "Generating file #262\n",
            "Generating file #186\n",
            "Generating file #263\n",
            "Generating file #187\n",
            "Generating file #264\n",
            "Generating file #188\n",
            "Generating file #265\n",
            "Generating file #266\n",
            "Generating file #189\n",
            "Generating file #267\n",
            "Generating file #190\n",
            "Generating file #268\n",
            "Generating file #191\n",
            "Generating file #269\n",
            "Generating file #192\n",
            "Generating file #193\n",
            "Generating file #194\n",
            "Generating file #270\n",
            "Generating file #195\n",
            "Generating file #196\n",
            "Generating file #271\n",
            "Generating file #197\n",
            "Generating file #272\n",
            "Generating file #198\n",
            "Generating file #273\n",
            "Generating file #199\n",
            "Generating file #274\n",
            "Generating file #200\n",
            "Generating file #275\n",
            "Generating file #201\n",
            "Generating file #202\n",
            "Generating file #276\n",
            "Generating file #203\n",
            "Generating file #277\n",
            "Generating file #204\n",
            "Generating file #278\n",
            "Generating file #279\n",
            "Generating file #205\n",
            "Generating file #206\n",
            "Generating file #280\n",
            "Generating file #207\n",
            "Generating file #208\n",
            "Generating file #209\n",
            "Generating file #281\n",
            "Generating file #282\n",
            "Generating file #283\n",
            "Generating file #284\n",
            "Generating file #210\n",
            "Generating file #285\n",
            "Generating file #211\n",
            "Generating file #286\n",
            "Generating file #212\n",
            "Generating file #287\n",
            "Generating file #213\n",
            "Generating file #288\n",
            "Generating file #214\n",
            "Generating file #289\n",
            "Generating file #215\n",
            "Generating file #290\n",
            "Generating file #216\n",
            "Generating file #291\n",
            "Generating file #292\n",
            "Generating file #217\n",
            "Generating file #293\n",
            "Generating file #218\n",
            "Generating file #294\n",
            "Generating file #219\n",
            "Generating file #295\n",
            "Generating file #220\n",
            "Generating file #296\n",
            "Generating file #221\n",
            "Generating file #297\n",
            "Generating file #298\n",
            "Generating file #222\n",
            "Generating file #223\n",
            "Generating file #299\n",
            "Generating file #224\n",
            "Generating file #300\n",
            "Generating file #375\n",
            "Generating file #301\n",
            "Generating file #376\n",
            "Generating file #302\n",
            "Generating file #377\n",
            "Generating file #303\n",
            "Generating file #378\n",
            "Generating file #379\n",
            "Generating file #304\n",
            "Generating file #380\n",
            "Generating file #305\n",
            "Generating file #381\n",
            "Generating file #306\n",
            "Generating file #382\n",
            "Generating file #307\n",
            "Generating file #383\n",
            "Generating file #308\n",
            "Generating file #384\n",
            "Generating file #309\n",
            "Generating file #385\n",
            "Generating file #310\n",
            "Generating file #386\n",
            "Generating file #311\n",
            "Generating file #387\n",
            "Generating file #312\n",
            "Generating file #313\n",
            "Generating file #388\n",
            "Generating file #314\n",
            "Generating file #315\n",
            "Generating file #389\n",
            "Generating file #316\n",
            "Generating file #390\n",
            "Generating file #317\n",
            "Generating file #318\n",
            "Generating file #391\n",
            "Generating file #319\n",
            "Generating file #320\n",
            "Generating file #392\n",
            "Generating file #321\n",
            "Generating file #393\n",
            "Generating file #322\n",
            "Generating file #323\n",
            "Generating file #394\n",
            "Generating file #395\n",
            "Generating file #324\n",
            "Generating file #396\n",
            "Generating file #325\n",
            "Generating file #397\n",
            "Generating file #326\n",
            "Generating file #398\n",
            "Generating file #399\n",
            "Generating file #327\n",
            "Generating file #328\n",
            "Generating file #400\n",
            "Generating file #401\n",
            "Generating file #329\n",
            "Generating file #402\n",
            "Generating file #330\n",
            "Generating file #403\n",
            "Generating file #331\n",
            "Generating file #404\n",
            "Generating file #332\n",
            "Generating file #405\n",
            "Generating file #333\n",
            "Generating file #406\n",
            "Generating file #334\n",
            "Generating file #407\n",
            "Generating file #408\n",
            "Generating file #335\n",
            "Generating file #409\n",
            "Generating file #336\n",
            "Generating file #410\n",
            "Generating file #337\n",
            "Generating file #411\n",
            "Generating file #338\n",
            "Generating file #412\n",
            "Generating file #339\n",
            "Generating file #413\n",
            "Generating file #340\n",
            "Generating file #414\n",
            "Generating file #341\n",
            "Generating file #342\n",
            "Generating file #415\n",
            "Generating file #343\n",
            "Generating file #416\n",
            "Generating file #344\n",
            "Generating file #417\n",
            "Generating file #418\n",
            "Generating file #419\n",
            "Generating file #345\n",
            "Generating file #420\n",
            "Generating file #346\n",
            "Generating file #421\n",
            "Generating file #347\n",
            "Generating file #348\n",
            "Generating file #422\n",
            "Generating file #349\n",
            "Generating file #350\n",
            "Generating file #423\n",
            "Generating file #351\n",
            "Generating file #424\n",
            "Generating file #352\n",
            "Generating file #425\n",
            "Generating file #353\n",
            "Generating file #354\n",
            "Generating file #426\n",
            "Generating file #355\n",
            "Generating file #427\n",
            "Generating file #356\n",
            "Generating file #428\n",
            "Generating file #357\n",
            "Generating file #358\n",
            "Generating file #429\n",
            "Generating file #359\n",
            "Generating file #430\n",
            "Generating file #360\n",
            "Generating file #431\n",
            "Generating file #361\n",
            "Generating file #432\n",
            "Generating file #362\n",
            "Generating file #433\n",
            "Generating file #363\n",
            "Generating file #364\n",
            "Generating file #365\n",
            "Generating file #366\n",
            "Generating file #434\n",
            "Generating file #367\n",
            "Generating file #435\n",
            "Generating file #436\n",
            "Generating file #368\n",
            "Generating file #369\n",
            "Generating file #437\n",
            "Generating file #370\n",
            "Generating file #438\n",
            "Generating file #439\n",
            "Generating file #371\n",
            "Generating file #440\n",
            "Generating file #372\n",
            "Generating file #441\n",
            "Generating file #373\n",
            "Generating file #374\n",
            "Generating file #442\n",
            "Generating file #450\n",
            "Generating file #443\n",
            "Generating file #451\n",
            "Generating file #444\n",
            "Generating file #452\n",
            "Generating file #445\n",
            "Generating file #453\n",
            "Generating file #446\n",
            "Generating file #454\n",
            "Generating file #447\n",
            "Generating file #455\n",
            "Generating file #448\n",
            "Generating file #456\n",
            "Generating file #449\n",
            "Generating file #457\n",
            "Generating file #525\n",
            "Generating file #458\n",
            "Generating file #526\n",
            "Generating file #459\n",
            "Generating file #527\n",
            "Generating file #460\n",
            "Generating file #528\n",
            "Generating file #461\n",
            "Generating file #529\n",
            "Generating file #462\n",
            "Generating file #530\n",
            "Generating file #531\n",
            "Generating file #463\n",
            "Generating file #464\n",
            "Generating file #532\n",
            "Generating file #465\n",
            "Generating file #533\n",
            "Generating file #466\n",
            "Generating file #534\n",
            "Generating file #467\n",
            "Generating file #535\n",
            "Generating file #536\n",
            "Generating file #468\n",
            "Generating file #537\n",
            "Generating file #469\n",
            "Generating file #470\n",
            "Generating file #471\n",
            "Generating file #538\n",
            "Generating file #472\n",
            "Generating file #473\n",
            "Generating file #539\n",
            "Generating file #474\n",
            "Generating file #540\n",
            "Generating file #475\n",
            "Generating file #541\n",
            "Generating file #476\n",
            "Generating file #477\n",
            "Generating file #542\n",
            "Generating file #478\n",
            "Generating file #543\n",
            "Generating file #479\n",
            "Generating file #544\n",
            "Generating file #545\n",
            "Generating file #480\n",
            "Generating file #481\n",
            "Generating file #482\n",
            "Generating file #546\n",
            "Generating file #483\n",
            "Generating file #547\n",
            "Generating file #484\n",
            "Generating file #548\n",
            "Generating file #485\n",
            "Generating file #549\n",
            "Generating file #486\n",
            "Generating file #550\n",
            "Generating file #487\n",
            "Generating file #488\n",
            "Generating file #551\n",
            "Generating file #489\n",
            "Generating file #552\n",
            "Generating file #553\n",
            "Generating file #490\n",
            "Generating file #554\n",
            "Generating file #491\n",
            "Generating file #555\n",
            "Generating file #556\n",
            "Generating file #492\n",
            "Generating file #557\n",
            "Generating file #558\n",
            "Generating file #493\n",
            "Generating file #559\n",
            "Generating file #494\n",
            "Generating file #560\n",
            "Generating file #495\n",
            "Generating file #496\n",
            "Generating file #497\n",
            "Generating file #498\n",
            "Generating file #561\n",
            "Generating file #562\n",
            "Generating file #499\n",
            "Generating file #500\n",
            "Generating file #563\n",
            "Generating file #501\n",
            "Generating file #564\n",
            "Generating file #502\n",
            "Generating file #565\n",
            "Generating file #503\n",
            "Generating file #504\n",
            "Generating file #566\n",
            "Generating file #567\n",
            "Generating file #505\n",
            "Generating file #568\n",
            "Generating file #506\n",
            "Generating file #569\n",
            "Generating file #570\n",
            "Generating file #507\n",
            "Generating file #508\n",
            "Generating file #571\n",
            "Generating file #572\n",
            "Generating file #509\n",
            "Generating file #573\n",
            "Generating file #510\n",
            "Generating file #511\n",
            "Generating file #574\n",
            "Generating file #512\n",
            "Generating file #575\n",
            "Generating file #513\n",
            "Generating file #514\n",
            "Generating file #576\n",
            "Generating file #577\n",
            "Generating file #515\n",
            "Generating file #516\n",
            "Generating file #578\n",
            "Generating file #517\n",
            "Generating file #579\n",
            "Generating file #518\n",
            "Generating file #580\n",
            "Generating file #519\n",
            "Generating file #520\n",
            "Generating file #581\n",
            "Generating file #521\n",
            "Generating file #582\n",
            "Generating file #522\n",
            "Generating file #583\n",
            "Generating file #523\n",
            "Generating file #584\n",
            "Generating file #524\n",
            "Generating file #585\n",
            "Generating file #586\n",
            "Generating file #587\n",
            "Generating file #588\n",
            "Generating file #589\n",
            "Generating file #590\n",
            "Generating file #591\n",
            "Generating file #592\n",
            "Generating file #593\n",
            "Generating file #594\n",
            "Generating file #595\n",
            "Generating file #596\n",
            "Generating file #597\n",
            "Generating file #598\n",
            "Generating file #599\n",
            "Of the 135 clean speech files analyzed, 0.0% had clipping, and 24.4% had low activity (below 60.0% active percentage)\n",
            "Of the 392 noise files analyzed, 17.9% had clipping, and 0.0% had low activity (below 0.0% active percentage)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}